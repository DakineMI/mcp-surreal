<!-- Generated by SpecStory, Markdown v2.0.0 -->

<!-- vscode Session 0b9cf11a-420d-4565-8994-7471b8d5d87f (2025-11-04 23:06Z) -->

# Running MCP server with multiple namespaces and databases (2025-11-04 23:06Z)

_**User (2025-11-04 23:13Z)**_

I want to run this mcp server with a single instance, multiple namespaces, and dbs

---

_**Agent (model copilot/claude-sonnet-4.5)**_

I'll help you understand how to run the SurrealMCP server with a single instance serving multiple namespaces and databases. Let me first check the current configuration options and then provide you with the setup instructions. Now let me check the tools to see how namespace and database switching works: Perfect! Based on my analysis of the code, **SurrealMCP already supports running a single instance with multiple namespaces and databases**. Here's how to set it up:

## Running SurrealMCP with Multiple Namespaces and Databases

The SurrealMCP server is designed to work with a single SurrealDB instance while allowing you to dynamically switch between multiple namespaces and databases using the built-in tools.

### Setup Options

#### Option 1: Start without pre-configured namespace/database (Recommended)

This allows maximum flexibility to switch between any namespace and database:

```bash
# Connect to a SurrealDB instance without specifying ns/db
surrealmcp start \
  --endpoint ws://localhost:8000/rpc \
  --user root \
  --pass root
```

Or with Docker:

```bash
docker run --rm -i --pull always \
  -e SURREALDB_URL="ws://localhost:8000/rpc" \
  -e SURREALDB_USER="root" \
  -e SURREALDB_PASS="root" \
  surrealdb/surrealmcp:latest start
```

#### Option 2: Start with a default namespace/database

You can optionally set a default namespace and database:

```bash
surrealmcp start \
  --endpoint ws://localhost:8000/rpc \
  --ns default_namespace \
  --db default_database \
  --user root \
  --pass root
```

### Switching Between Namespaces and Databases

Once the server is running, use the available tools to switch contexts:

**Available Tools:**
- `use_namespace` - Switch to a different namespace
- `use_database` - Switch to a different database  
- `list_namespaces` - List all available namespaces
- `list_databases` - List all available databases

**Example workflow in your AI assistant:**

```
1. "List all namespaces"
   → Uses list_namespaces tool

2. "Switch to the 'production' namespace"
   → Uses use_namespace('production')

3. "List databases in this namespace"
   → Uses list_databases tool

4. "Switch to the 'analytics' database"
   → Uses use_database('analytics')

5. "Query all users"
   → Uses select(["user"]) or query("SELECT * FROM user")
```

### Example Configuration for Common Scenarios

**For development with multiple projects:**

```json
{
  "mcpServers": {
    "SurrealDB": {
      "command": "surrealmcp",
      "args": ["start"],
      "env": {
        "SURREALDB_URL": "ws://localhost:8000/rpc",
        "SURREALDB_USER": "root",
        "SURREALDB_PASS": "root"
      }
    }
  }
}
```

Then switch between:
- Namespace: `project_a`, `project_b`, `project_c`
- Databases: `development`, `staging`, `production`

### Key Benefits

✅ **Single instance** - One MCP server connects to one SurrealDB instance  
✅ **Multiple namespaces** - Dynamically switch using `use_namespace` tool  
✅ **Multiple databases** - Dynamically switch using `use_database` tool  
✅ **No reconnection needed** - Context switching is instant  
✅ **Flexible access** - Query across different namespaces and databases in the same session

The architecture is already designed for your use case - no code changes needed!

---

_**User (2025-11-05 00:01Z)**_

That's not going to work with with agiants working in parallel in different namespaces and databases, so we are going to update the tools and parameters:

- disable all cloud hosted related tools to prevent acidental calls. Absense or the default false prevent usage. Must receive a flag with a true value to enable them probablly in an env variable.
- Make sure http transport enabled
-  Namespace should have an enum with AGENT_MEMORY, RECIPES, others may be added later.
- Database should be the the name of the workspace. 
- automatically or make then parameters

---

_**Agent (model copilot/claude-sonnet-4.5)**_

I'll help you modify SurrealMCP to support multiple agents working in parallel with workspace-specific isolation. Let me create a plan and implement the changes. Let me check the cloud-related tools to understand their structure: Now let me check where the tools are registered: Let me find where the tool router is defined: Now let me start implementing the changes. Let me update the todo and begin: Let me start by adding the namespace enum and updating the CLI parameters: 
```

```

```

```
Now update the `main.rs` to pass these new parameters: 
```

```
Now I need to add the `enable_cloud_tools` field to `ServerConfig`: 
```

```
Let me find and fix that location: 
```

```
Now I need to pass the enable_cloud_tools flag to the SurrealService. Let me check where SurrealService is created: Let me check the with_config signature: Now I need to add enable_cloud_tools to SurrealService struct and with_config: 
```

```

```

```
Now I need to update the with_config function signature and add enable_cloud_tools parameter: 
```

```

```

```
Now I need to update all the calls to `with_config` to pass the `enable_cloud_tools` parameter: 
```

```

```

```

```

```
Now I need to add the check in each cloud-related tool. Let me find all the cloud tools: Now let me add the cloud tools guard. Let me read one of the cloud tools to understand the structure: Perfect! Now I'll add the guard check at the beginning of each cloud tool. Let me update them systematically: 
```

```

```

```


---

_**User (2025-11-05 00:02Z)**_

Can't add the storage type and project name to start, need to add them as required params on all the other tool calls, then make sure each tool call instance targets the correct namespace and db 

---

_**Agent (model copilot/claude-sonnet-4.5)**_

I understand now - instead of setting namespace/database at startup, we need to make them required parameters on each tool call so that multiple agents can work in parallel with different namespaces and databases. Let me refactor this approach. 

---

